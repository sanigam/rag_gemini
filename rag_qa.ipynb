{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import requests\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "import traceback\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "#!pip install pypdf, langchain, chromadb, sentence-transformers\n",
    "#!pip install --upgrade --quiet  langchain-google-genai pillow\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOOGLE_API_KEY = \"AIzaSyBc3QhhSZbhfaqOAponIDb3SVF91h7eubE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a boomerang that doesn't come back?\n",
      "\n",
      "A stick.\n"
     ]
    }
   ],
   "source": [
    "## LLM model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "print(llm.invoke(\"tell me a joke\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./articles_rep/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "#print( dict(texts[100])['metadata']['source'], ', Page:', dict(texts[100])['metadata']['page'], '\\n', dict(texts[10])['page_content'], dict(texts[100])['metadata']['source'])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 84\n"
     ]
    }
   ],
   "source": [
    "chroma_dir = './chroma_db'\n",
    "shutil.rmtree(chroma_dir, ignore_errors=True)\n",
    "#Store in vector database\n",
    "client = chromadb.PersistentClient(path=chroma_dir)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma(client=client, embedding_function=embedding_function, collection_name=\"articles_embeddings\")\n",
    "vectordb_ids = vectordb.add_documents(texts)\n",
    "print(f\"Number of chunks created: {len(vectordb_ids)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_dir = './chroma_db'\n",
    "shutil.rmtree(chroma_dir, ignore_errors=True)\n",
    "filter_list = []\n",
    "#Make a retrieval object\n",
    "client = chromadb.PersistentClient(path=chroma_dir)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma(client=client, embedding_function=embedding_function, collection_name=\"articles_embeddings\")\n",
    "doc_list = list(set( [ meta['source'] for meta  in vectordb.get()['metadatas'] ]))\n",
    "\n",
    "\n",
    "for doc in doc_list:\n",
    "    filter_list.append({\"source\": doc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM output with ref to sources\n",
    "def llm_output(llm_response):\n",
    "    print(\"Answer from LLM:\",llm_response['answer'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"context\"]:\n",
    "         print(source.metadata['source'], ' Page:', source.metadata['page'] )\n",
    "        #print(source.metadata['source'], ' Page:', source.metadata['page'],'\\n', source.page_content, '\\n','\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m SentenceTransformerEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m Chroma(client\u001b[38;5;241m=\u001b[39mclient, embedding_function\u001b[38;5;241m=\u001b[39membedding_function, collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfilter_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_list' is not defined"
     ]
    }
   ],
   "source": [
    "chroma_dir = './chroma_db'\n",
    "shutil.unpack_archive(\"chroma_db.zip\", \".\")\n",
    "client = chromadb.PersistentClient(path=chroma_dir)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma(client=client, embedding_function=embedding_function, collection_name=\"articles_embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the prompt template and retrieval chain\n",
    "template = \"\"\"\n",
    "You are a helpful AI assistant.\n",
    "Answer based on the context provided. \n",
    "context: {context}\n",
    "input: {input}\n",
    "answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKfX4vX-5RFT",
    "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How to prevent childhood  obesity?\n",
      "Answer from LLM: Key interventions for reducing the risk of unhealthy weight gain in childhood include: \n",
      "\n",
      "(1) addressing early life exposures to improve nutritional status and growth patterns, \n",
      "(2) improving community understanding and social norms, \n",
      "(3) addressing exposure of children to marketing of foods, \n",
      "(4) influencing the food system and food environment, and \n",
      "(5) improving nutrition in neighborhoods.\n",
      "\n",
      "\n",
      "Sources:\n",
      "articles_rep/who-discussion-paper-on-obesity---final190821.pdf  Page: 3\n",
      "articles_rep/who-discussion-paper-on-obesity---final190821.pdf  Page: 2\n",
      "articles_rep/who-discussion-paper-on-obesity---final190821.pdf  Page: 3\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Query and output\n",
    "query = \"How to prevent childhood  obesity?\"\n",
    "# query = \"What are  symptoms of obesity\"\n",
    "# query = \"How to address obesity?\"\n",
    "\n",
    "print(\"Query:\", query)\n",
    "llm_response = retrieval_chain.invoke({\"input\":query})\n",
    "\n",
    "print(llm_output( llm_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
